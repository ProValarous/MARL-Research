state_space =  Box(-inf, inf, (62,), float32)
observation_space =  {'adversary_0': Box(-inf, inf, (16,), float32), 'adversary_1': Box(-inf, inf, (16,), float32), 'adversary_2': Box(-inf, inf, (16,), float32), 'agent_0': Box(-inf, inf, (14,), float32)}
action_space =  {'adversary_0': Discrete(5), 'adversary_1': Discrete(5), 'adversary_2': Discrete(5), 'agent_0': Discrete(5)}
======================================

Agent= adversary_0
Observation :  [ 0.          0.          0.5479121  -0.12224312 -1.2173076   0.03293781
 -0.7804757   0.8904201   0.16928375  0.51697916 -1.3595574   1.0734879
 -0.02563269  0.69437176  0.          0.        ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [ 0.          0.          0.71719587  0.39473605 -1.3865913  -0.48404136
 -0.9497594   0.37344092 -0.16928375 -0.51697916 -1.5288411   0.55650866
 -0.19491644  0.17739256  0.          0.        ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_2
Observation :  [ 0.          0.         -0.8116453   0.9512447   0.14224984 -1.04055
  0.5790818  -0.18306772  1.3595574  -1.0734879   1.5288411  -0.55650866
  1.3339247  -0.3791161   0.          0.        ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [ 0.          0.          0.5222794   0.5721286  -1.1916748  -0.66143394
 -0.75484294  0.19604836  0.02563269 -0.69437176  0.19491644 -0.17739256
 -1.3339247   0.3791161 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_0
Observation :  [-0.         -0.          0.5479121  -0.12224312 -1.2173076   0.03293781
 -0.7804757   0.8904201   0.16928375  0.51697916 -1.3595574   1.0734879
 -0.02563269  0.69437176  0.4         0.        ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_1
Observation :  [-0.3        -0.          0.71719587  0.39473605 -1.3865913  -0.48404136
 -0.9497594   0.37344092 -0.16928375 -0.51697916 -1.5288411   0.55650866
 -0.19491644  0.17739256  0.4         0.        ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_2
Observation :  [-0.         -0.3        -0.8116453   0.9512447   0.14224984 -1.04055
  0.5790818  -0.18306772  1.3595574  -1.0734879   1.5288411  -0.55650866
  1.3339247  -0.3791161   0.4         0.        ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= agent_0
Observation :  [ 0.4         0.          0.5222794   0.5721286  -1.1916748  -0.66143394
 -0.75484294  0.19604836  0.02563269 -0.69437176  0.19491644 -0.17739256
 -1.3339247   0.3791161 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_0
Observation :  [ 0.3        -0.          0.5479121  -0.12224312 -1.2173076   0.03293781
 -0.7804757   0.8904201   0.13928375  0.51697916 -1.3595574   1.0434878
  0.01436731  0.69437176  0.3        -0.4       ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_1
Observation :  [-0.225      -0.3         0.68719584  0.39473605 -1.3565913  -0.48404136
 -0.9197594   0.37344092 -0.13928375 -0.51697916 -1.4988412   0.5265086
 -0.12491643  0.17739256  0.3        -0.4       ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_2
Observation :  [-0.          0.075      -0.8116453   0.9212447   0.14224984 -1.01055
  0.5790818  -0.15306772  1.3595574  -1.0434878   1.4988412  -0.5265086
  1.3739247  -0.3491161   0.3        -0.4       ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= agent_0
Observation :  [ 0.3        -0.4         0.5622794   0.5721286  -1.2316749  -0.66143394
 -0.79484296  0.19604836 -0.01436731 -0.69437176  0.12491643 -0.17739256
 -1.3739247   0.3491161 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_0
Observation :  [ 0.225      -0.3         0.5779121  -0.12224312 -1.2473075   0.03293781
 -0.81047565  0.8904201   0.08678374  0.4869792  -1.3895574   1.0509878
  0.01436731  0.65437174  0.225      -0.3       ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [-0.46875    -0.225       0.66469586  0.36473605 -1.3340913  -0.45404136
 -0.8972594   0.40344092 -0.08678374 -0.4869792  -1.4763411   0.56400865
 -0.07241643  0.16739255  0.225      -0.3       ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_2
Observation :  [ 0.3         0.05625    -0.8116453   0.9287447   0.14224984 -1.0180501
  0.5790818  -0.16056773  1.3895574  -1.0509878   1.4763411  -0.56400865
  1.4039247  -0.3966161   0.225      -0.3       ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [ 0.225      -0.3         0.5922794   0.53212863 -1.2616749  -0.6214339
 -0.824843    0.23604837 -0.01436731 -0.65437174  0.07241643 -0.16739255
 -1.4039247   0.3966161 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [ 0.16875    -0.225       0.6004121  -0.15224312 -1.2698076   0.06293781
 -0.8329756   0.9204201   0.01740874  0.49447918 -1.3820574   1.0866128
  0.01436731  0.65437174  0.16875     0.175     ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [-0.0515625  -0.16875     0.61782086  0.34223607 -1.2872163  -0.43154138
 -0.8503844   0.42594093 -0.01740874 -0.49447918 -1.3994662   0.59213364
 -0.00304144  0.15989256  0.16875     0.175     ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_2
Observation :  [ 0.225       0.0421875  -0.7816453   0.9343697   0.11224984 -1.023675
  0.54908174 -0.16619273  1.3820574  -1.0866128   1.3994662  -0.59213364
  1.3964247  -0.43224108  0.16875     0.175     ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [ 0.16875     0.175       0.6147794   0.5021286  -1.2841749  -0.59143394
 -0.84734297  0.26604837 -0.01436731 -0.65437174  0.00304144 -0.15989256
 -1.3964247   0.43224108]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [ 0.1265625  -0.16875     0.6172871  -0.17474312 -1.2866826   0.08543781
 -0.84985065  0.9429201  -0.00462251  0.5001042  -1.3764324   1.1133316
  0.01436731  0.69437176  0.1265625   0.53125   ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_1
Observation :  [-0.03867187 -0.1265625   0.6126646   0.32536107 -1.28206    -0.41466638
 -0.84522814  0.44281593  0.00462251 -0.5001042  -1.3718098   0.61322737
  0.01898981  0.19426756  0.1265625   0.53125   ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_2
Observation :  [ 0.16875     0.03164063 -0.7591453   0.93858844  0.08974984 -1.0278938
  0.52658176 -0.17041147  1.3764324  -1.1133316   1.3718098  -0.61322737
  1.3907998  -0.41895986  0.1265625   0.53125   ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [ 0.1265625   0.53125     0.6316544   0.5196286  -1.3010498  -0.6089339
 -0.86421794  0.24854837 -0.01436731 -0.69437176 -0.01898981 -0.19426756
 -1.3907998   0.41895986]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_0
Observation :  [ 0.39492187 -0.1265625   0.6299434  -0.19161811 -1.2993388   0.10231281
 -0.8625069   0.9597951  -0.02114595  0.50432295 -1.3722136   1.1333706
  0.01436731  0.76437175  0.09492187 -0.0015625 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_1
Observation :  [ 0.2709961  -0.09492187  0.60879743  0.3127048  -1.2781929  -0.4020101
 -0.841361    0.45547217  0.02114595 -0.50432295 -1.3510677   0.6290477
  0.03551325  0.2600488   0.09492187 -0.0015625 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_2
Observation :  [ 0.1265625  -0.27626953 -0.7422703   0.9417525   0.07287484 -1.0310578
  0.50970674 -0.17357554  1.3722136  -1.1333706   1.3510677  -0.6290477
  1.386581   -0.36899891  0.09492187 -0.0015625 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [ 0.09492187 -0.0015625   0.64431065  0.5727536  -1.3137062  -0.66205895
 -0.8768742   0.19542336 -0.01436731 -0.76437175 -0.03551325 -0.2600488
 -1.386581    0.36899891]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_0
Observation :  [ 5.9619141e-01 -9.4921872e-02  6.6943556e-01 -2.0427437e-01
 -1.3388309e+00  1.1496906e-01 -9.0199912e-01  9.7245133e-01
 -3.3538524e-02  5.0748700e-01 -1.3990496e+00  1.1184000e+00
 -1.5632693e-02  7.7687174e-01 -3.2880861e-01 -1.1718750e-03]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_1
Observation :  [ 2.0324707e-01 -7.1191408e-02  6.3589704e-01  3.0321261e-01
 -1.3052925e+00 -3.9251792e-01 -8.6846060e-01  4.6496436e-01
  3.3538524e-02 -5.0748700e-01 -1.3655111e+00  6.1091292e-01
  1.7905829e-02  2.6938474e-01 -3.2880861e-01 -1.1718750e-03]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_2
Observation :  [ 9.4921872e-02 -2.0720215e-01 -7.2961408e-01  9.1412556e-01
  6.0218591e-02 -1.0034308e+00  4.9705049e-01 -1.4594859e-01
  1.3990496e+00 -1.1184000e+00  1.3655111e+00 -6.1091292e-01
  1.3834169e+00 -3.4152821e-01 -3.2880861e-01 -1.1718750e-03]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [-3.2880861e-01 -1.1718750e-03  6.5380281e-01  5.7259738e-01
 -1.3231983e+00 -6.6190267e-01 -8.8636643e-01  1.9557962e-01
  1.5632693e-02 -7.7687174e-01 -1.7905829e-02 -2.6938474e-01
 -1.3834169e+00  3.4152821e-01]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [ 0.74714357 -0.07119141  0.7290547  -0.21376656 -1.3984501   0.12446125
 -0.96161824  0.98194355 -0.07283296  0.50986004 -1.4491765   1.1071719
 -0.10813269  0.7862467  -0.24660644  0.3991211 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_1
Observation :  [ 0.1524353  -0.35339355  0.65622175  0.2960935  -1.3256172  -0.3853988
 -0.8887853   0.4720835   0.07283296 -0.50986004 -1.3763436   0.59731185
 -0.03529974  0.27638668 -0.24660644  0.3991211 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_2
Observation :  [ 0.07119141 -0.4554016  -0.72012186  0.8934053   0.05072641 -0.98271066
  0.4875583  -0.12522838  1.4491765  -1.1071719   1.3763436  -0.59731185
  1.3410438  -0.32092518 -0.24660644  0.3991211 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [-0.24660644  0.3991211   0.62092197  0.5724802  -1.2903174  -0.6617855
 -0.8534855   0.1956968   0.10813269 -0.7862467   0.03529974 -0.27638668
 -1.3410438   0.32092518]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [ 0.86035764 -0.05339355  0.80376905 -0.2208857  -1.4731644   0.13158038
 -1.0363326   0.98906267 -0.13230377  0.48163983 -1.5167718   1.0687509
 -0.2075077   0.833278   -0.18495484  0.6993408 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_1
Observation :  [ 0.4143265  -0.26504517  0.6714653   0.26075414 -1.3408607  -0.35005945
 -0.90402883  0.50742286  0.13230377 -0.48163983 -1.384468    0.58711106
 -0.07520391  0.35163817 -0.18495484  0.6993408 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_2
Observation :  [ 0.05339355 -0.3415512  -0.71300274  0.84786516  0.04360726 -0.9371705
  0.48043916 -0.07968821  1.5167718  -1.0687509   1.384468   -0.58711106
  1.3092641  -0.2354729  -0.18495484  0.6993408 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [-0.18495484  0.6993408   0.5962613   0.6123923  -1.2656568  -0.7016976
 -0.8288249   0.1557847   0.2075077  -0.833278    0.07520391 -0.35163817
 -1.3092641   0.2354729 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_0
Observation :  [ 0.64526826  0.25995484  0.8898048  -0.22622505 -1.5592003   0.13691974
 -1.1223683   0.99440205 -0.1769069   0.46047467 -1.5974681   1.0399351
 -0.31203893  0.9085514  -0.13871613  0.5245056 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [ 0.01074486 -0.19878387  0.7128979   0.2342496  -1.3822933  -0.32355493
 -0.94546145  0.5339274   0.1769069  -0.46047467 -1.4205613   0.57946044
 -0.13513204  0.44807675 -0.13871613  0.5245056 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_2
Observation :  [ 0.04004516 -0.55616343 -0.70766336  0.8137101   0.03826791 -0.9030154
  0.4750998  -0.04553309  1.5974681  -1.0399351   1.4205613  -0.57946044
  1.2854292  -0.1313837  -0.13871613  0.5245056 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [-0.13871613  0.5245056   0.5777659   0.6823264  -1.2471613  -0.77163166
 -0.81032944  0.08585062  0.31203893 -0.9085514   0.13513204 -0.44807675
 -1.2854292   0.1313837 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_0
Observation :  [ 0.48395118  0.19496612  0.95433164 -0.20022957 -1.6237271   0.11092426
 -1.1868951   0.96840656 -0.24035925  0.4146008  -1.6579905   0.9583233
 -0.3904374   0.9350065  -0.10403709  0.3933792 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_1
Observation :  [ 0.00805864 -0.44908792  0.7139724   0.21437122 -1.3833679  -0.30367655
 -0.94653594  0.55380577  0.24035925 -0.4146008  -1.4176313   0.5437225
 -0.15007815  0.5204057  -0.10403709  0.3933792 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_2
Observation :  [ 0.03003388 -0.71712255 -0.7036589   0.7580937   0.03426339 -0.84739906
  0.4710953   0.01008325  1.6579905  -0.9583233   1.4176313  -0.5437225
  1.2675531  -0.0233168  -0.10403709  0.3933792 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [-0.10403709  0.3933792   0.5638942   0.7347769  -1.2332897  -0.82408226
 -0.7964578   0.03340006  0.3904374  -0.9350065   0.15007815 -0.5204057
 -1.2675531   0.0233168 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [ 0.06296339  0.14622459  1.0027268  -0.18073297 -1.6721222   0.09142765
 -1.2352903   0.94890994 -0.2879485   0.35019538 -1.7033823   0.8671144
 -0.4492362   0.9548478  -0.07802782  0.6950344 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_1
Observation :  [ 0.00604398 -0.03681593  0.71477824  0.16946243 -1.3841738  -0.25876775
 -0.9473418   0.59871453  0.2879485  -0.35019538 -1.4154338   0.516919
 -0.16128771  0.6046524  -0.07802782  0.6950344 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_2
Observation :  [ 0.02252541 -0.8378419  -0.70065546  0.68638146  0.03126001 -0.7756868
  0.4680919   0.08179551  1.7033823  -0.8671144   1.4154338  -0.516919
  1.254146    0.08773338 -0.07802782  0.6950344 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [-0.07802782  0.6950344   0.5534905   0.77411485 -1.222886   -0.8634202
 -0.7860541  -0.00593787  0.4492362  -0.9548478   0.16128771 -0.6046524
 -1.254146   -0.08773338]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_0
Observation :  [ 0.04722254 -0.19033155  1.0090231  -0.1661105  -1.6784185   0.07680519
 -1.2415867   0.9342875  -0.29364043  0.33189133 -1.707426    0.76870775
 -0.46333534  1.0097288  -0.45852086  0.5212758 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_1
Observation :  [ 0.00453299 -0.02761195  0.71538264  0.16578084 -1.3847781  -0.25508615
 -0.9479462   0.60239613  0.29364043 -0.33189133 -1.4137856   0.43681645
 -0.1696949   0.67783743 -0.45852086  0.5212758 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_2
Observation :  [ 0.01689405 -0.62838143 -0.69840294  0.6025973   0.02900746 -0.6919026
  0.46583936  0.1655797   1.707426   -0.76870775  1.4137856  -0.43681645
  1.2440907   0.241021   -0.45852086  0.5212758 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [-0.45852086  0.5212758   0.54568774  0.8436183  -1.2150832  -0.9329236
 -0.7782513  -0.07544131  0.46333534 -1.0097288   0.1696949  -0.67783743
 -1.2440907  -0.241021  ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_0
Observation :  [-0.26458308 -0.14274867  1.0137453  -0.18514365 -1.6831408   0.09583835
 -1.2463089   0.9533206  -0.29790938  0.3481633  -1.7104589   0.7249028
 -0.5139097   1.0808895  -0.74389064  0.39095685]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_1
Observation :  [-0.29660025 -0.02070896  0.7158359   0.16301964 -1.3852314  -0.25232497
 -0.9483995   0.6051573   0.29790938 -0.3481633  -1.4125495   0.3767395
 -0.21600027  0.7327262  -0.74389064  0.39095685]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_2
Observation :  [ 0.01267054 -0.4712861  -0.6967135   0.53975916  0.02731806 -0.62906444
  0.46414995  0.22841784  1.7104589  -0.7249028   1.4125495  -0.3767395
  1.1965492   0.35598674 -0.74389064  0.39095685]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [-0.74389064  0.39095685  0.49983567  0.8957459  -1.1692312  -0.98505116
 -0.7323992  -0.12756889  0.5139097  -1.0808895   0.21600027 -0.7327262
 -1.1965492  -0.35598674]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_0
Observation :  [-0.19843732  0.1929385   0.98728704 -0.19941851 -1.6566825   0.11011321
 -1.2198505   0.9675955  -0.3011111   0.36036727 -1.6827335   0.692049
 -0.5618404   1.13426    -0.957918    0.29321763]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [-0.2224502  -0.01553172  0.68617594  0.16094875 -1.3555714  -0.25025406
 -0.9187395   0.6072282   0.3011111  -0.36036727 -1.3816224   0.3316818
 -0.2607293   0.7738928  -0.957918    0.29321763]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_2
Observation :  [ 0.00950291 -0.35346454 -0.6954465   0.49263054  0.02605101 -0.5819358
  0.4628829   0.27554646  1.6827335  -0.692049    1.3816224  -0.3316818
  1.1208931   0.44221103 -0.957918    0.29321763]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [-0.957918    0.29321763  0.4254466   0.9348416  -1.0948421  -1.0241469
 -0.6580102  -0.16666457  0.5618404  -1.13426     0.2607293  -0.7738928
 -1.1208931  -0.44221103]
Reward: -0.34841554107832073
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [-0.14882798  0.14470388  0.9674433  -0.18012467 -1.6368388   0.09081936
 -1.2000068   0.9483017  -0.3035124   0.33952025 -1.6619395   0.63740873
 -0.6377885   1.144288   -0.7184385   0.6199132 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [-0.16683765 -0.3116488   0.6639309   0.15939558 -1.3333263  -0.24870089
 -0.89649445  0.6087814   0.3035124  -0.33952025 -1.358427    0.2978885
 -0.3342761   0.8047677  -0.7184385   0.6199132 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_2
Observation :  [ 0.00712718 -0.5650984  -0.69449615  0.45728406  0.02510072 -0.5465894
  0.46193263  0.3108929   1.6619395  -0.63740873  1.358427   -0.2978885
  1.024151    0.50687927 -0.7184385   0.6199132 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= agent_0
Observation :  [-0.7184385   0.6199132   0.3296548   0.9641633  -0.99905026 -1.0534686
 -0.56221837 -0.19598635  0.6377885  -1.144288    0.3342761  -0.8047677
 -1.024151   -0.50687927]
Reward: -0.6416331821935095
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_0
Observation :  [-0.11162099  0.10852791  0.9525605  -0.16565429 -1.621956    0.07634897
 -1.185124    0.9338313  -0.30531335  0.293885   -1.646344    0.5664285
 -0.69474953  1.1918089  -0.9388289   0.46493492]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [-0.42512822 -0.23373659  0.64724714  0.12823069 -1.3166426  -0.217536
 -0.8798107   0.6399463   0.30531335 -0.293885   -1.3410306   0.27254352
 -0.3894362   0.89792395 -0.9388289   0.46493492]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_2
Observation :  [ 0.00534538 -0.12382381 -0.69378346  0.40077424  0.024388   -0.49007955
  0.4612199   0.36740276  1.646344   -0.5664285   1.3410306  -0.27254352
  0.9515944   0.6253804  -0.9388289   0.46493492]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [-0.9388289   0.46493492  0.25781095  1.0261546  -0.9272064  -1.1154599
 -0.4903745  -0.25797766  0.69474953 -1.1918089   0.3894362  -0.89792395
 -0.9515944  -0.6253804 ]
Reward: -1.053701583693993
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_0
Observation :  [-0.08371574  0.08139593  0.9413984  -0.15480149 -1.6107938   0.06549618
 -1.173962    0.92297846 -0.33666408  0.25965852 -1.6346474   0.54319334
 -0.77747035  1.2274497  -0.30412164  0.34870118]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_1
Observation :  [-0.31884617 -0.47530246  0.6047343   0.10485703 -1.2741297  -0.19416235
 -0.83729786  0.66331995  0.33666408 -0.25965852 -1.2979833   0.28353482
 -0.44080624  0.9677911  -0.30412164  0.34870118]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_2
Observation :  [ 0.00400904 -0.09286786 -0.6932489   0.38839185  0.02385346 -0.47769716
  0.46068537  0.37978512  1.6346474  -0.54319334  1.2979833  -0.28353482
  0.85717696  0.6842563  -0.30412164  0.34870118]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= agent_0
Observation :  [-0.30412164  0.34870118  0.16392806  1.0726482  -0.83332354 -1.1619534
 -0.39649162 -0.30447116  0.77747035 -1.2274497   0.44080624 -0.9677911
 -0.85717696 -0.6842563 ]
Reward: -1.1563821176512155
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [-0.06278681 -0.23895305  0.9330268  -0.14666189 -1.6024222   0.05735659
 -1.1655904   0.91483885 -0.36017713  0.20398869 -1.6258749   0.52576697
 -0.7995109   1.2541802  -0.22809124  0.6615259 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_1
Observation :  [-0.23913462 -0.05647684  0.5728497   0.05732679 -1.2422452  -0.1466321
 -0.80541325  0.7108502   0.36017713 -0.20398869 -1.2656977   0.32177827
 -0.4393338   1.0501914  -0.22809124  0.6615259 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_2
Observation :  [ 0.30300677 -0.0696509  -0.692848    0.37910506  0.02345255 -0.46841037
  0.46028447  0.3890719   1.6258749  -0.52576697  1.2656977  -0.32177827
  0.8263639   0.72841316 -0.22809124  0.6615259 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= agent_0
Observation :  [-0.22809124  0.6615259   0.1335159   1.1075182  -0.80291134 -1.1968236
 -0.36607945 -0.33934128  0.7995109  -1.2541802   0.4393338  -1.0501914
 -0.8263639  -0.72841316]
Reward: -1.2399071598193458
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_0
Observation :  [-0.3470901  -0.17921479  0.92674816 -0.1705572  -1.5961436   0.08125189
 -1.1593117   0.9387342  -0.3778119   0.2222363  -1.5892955   0.5426972
 -0.81604135  1.344228   -0.5710684   0.4961444 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_1
Observation :  [-0.47935098 -0.04235762  0.54893625  0.05167911 -1.2183317  -0.14098442
 -0.7814998   0.7164979   0.3778119  -0.2222363  -1.2114836   0.32046086
 -0.43822944  1.1219918  -0.5710684   0.4961444 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_2
Observation :  [ 0.52725506 -0.05223817 -0.66254735  0.37213996 -0.00684812 -0.46144527
  0.4299838   0.396037    1.5892955  -0.5426972   1.2114836  -0.32046086
  0.7732541   0.8015309  -0.5710684   0.4961444 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= agent_0
Observation :  [-0.5710684   0.4961444   0.11070678  1.1736709  -0.78010225 -1.2629762
 -0.34327033 -0.40549386  0.81604135 -1.344228    0.43822944 -1.1219918
 -0.7732541  -0.8015309 ]
Reward: -1.4153002289880539
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_0
Observation :  [-0.2603176   0.16558892  0.8920391  -0.18847868 -1.5614346   0.09917337
 -1.1246027   0.9566557  -0.391038    0.23592202 -1.501861    0.5553948
 -0.8384392   1.411764   -0.8283013   0.3721083 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [-0.35951322 -0.3317682   0.5010011   0.04744335 -1.1703966  -0.13674866
 -0.7335647   0.72073364  0.391038   -0.23592202 -1.1108229   0.31947282
 -0.4474012   1.1758419  -0.8283013   0.3721083 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= adversary_2
Observation :  [ 0.39544132 -0.33917862 -0.60982186  0.36691615 -0.05957363 -0.45622146
  0.37725827  0.40126082  1.501861   -0.5553948   1.1108229  -0.31947282
  0.66342175  0.85636914 -0.8283013   0.3721083 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= agent_0
Observation :  [-0.8283013   0.3721083   0.05359993  1.2232853  -0.7229954  -1.3125906
 -0.28616348 -0.4551083   0.8384392  -1.411764    0.4474012  -1.1758419
 -0.66342175 -0.85636914]
Reward: -1.562942978504844
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_0
Observation :  [-0.19523819  0.12419168  0.8660074  -0.1719198  -1.5354028   0.08261448
 -1.098571    0.9400968  -0.40095755  0.18618631 -1.436285    0.5049181
 -0.89523757  1.432416   -0.621226    0.27908123]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_1
Observation :  [ 0.03036508 -0.24882616  0.4650498   0.01426652 -1.1344453  -0.10357183
 -0.69761336  0.7539105   0.40095755 -0.18618631 -1.0353276   0.31873176
 -0.49428     1.2462296  -0.621226    0.27908123]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_2
Observation :  [ 0.29658097 -0.25438398 -0.5702777   0.3329983  -0.09911776 -0.42230362
  0.33771414  0.4351787   1.436285   -0.5049181   1.0353276  -0.31873176
  0.5410475   0.9274978  -0.621226    0.27908123]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  2
Agent= agent_0
Observation :  [-0.621226    0.27908123 -0.0292302   1.2604961  -0.64016527 -1.3498014
 -0.20333336 -0.49231914  0.89523757 -1.432416    0.49428    -1.2462296
 -0.5410475  -0.9274978 ]
Reward: -1.6836974392857698
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [-0.14642864  0.09314376  0.8464835  -0.15950063 -1.515879    0.07019531
 -1.0790471   0.92767763 -0.37839723  0.14888453 -1.3871032   0.4670605
 -0.93783635  1.4479048  -0.4659195   0.6093109 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_1
Observation :  [ 0.02277381 -0.18661962  0.4680863  -0.01061609 -1.1374818  -0.07868922
 -0.70064986  0.7787931   0.37839723 -0.14888453 -1.008706    0.318176
 -0.5594391   1.2990203  -0.4659195   0.6093109 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  0
Agent= adversary_2
Observation :  [ 0.5224357  -0.19078799 -0.5406196   0.3075599  -0.12877586 -0.39686522
  0.30805606  0.4606171   1.3871032  -0.4670605   1.008706   -0.318176
  0.4492668   0.9808443  -0.4659195   0.6093109 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= agent_0
Observation :  [-0.4659195   0.6093109  -0.0913528   1.2884042  -0.5780427  -1.3777095
 -0.14121076 -0.52022725  0.93783635 -1.4479048   0.5594391  -1.2990203
 -0.4492668  -0.9808443 ]
Reward: -1.7803473382630044
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_0
Observation :  [-0.10982148 -0.23014218  0.8318407  -0.15018626 -1.5012362   0.06088094
 -1.0644042   0.9183632  -0.361477    0.12090819 -1.3202167   0.43866736
 -0.96978545  1.4995216  -0.34943962  0.0569832 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  3
Agent= adversary_1
Observation :  [ 0.01708036 -0.13996471  0.4703637  -0.02927805 -1.1397592  -0.06002726
 -0.70292723  0.797455    0.361477   -0.12090819 -0.9587397   0.31775916
 -0.60830843  1.3786134  -0.34943962  0.0569832 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  1
Agent= adversary_2
Observation :  [ 0.3918268   0.15690902 -0.48837602  0.2884811  -0.18101944 -0.3777864
  0.25581247  0.4796959   1.3202167  -0.43866736  0.9587397  -0.31775916
  0.35043126  1.0608542  -0.34943962  0.0569832 ]
Reward: 0.0
Termination:  False
Truncation False
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= agent_0
Observation :  [-0.34943962  0.0569832  -0.13794474  1.3493353  -0.5314507  -1.4386406
 -0.0946188  -0.58115834  0.96978545 -1.4995216   0.60830843 -1.3786134
 -0.35043126 -1.0608542 ]
Reward: -2.011077533244809
Termination:  False
Truncation False
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

action =  4
Agent= adversary_0
Observation :  [-0.08236611 -0.47260663  0.82085854 -0.17320047 -1.490254    0.08389515
 -1.0534221   0.94137746 -0.3487868   0.12992594 -1.2700518   0.47737247
 -0.99374723  1.5282341  -0.26207972  0.4427374 ]
Reward: 0.0
Termination:  False
Truncation True
Selected Agent:  adversary_0
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

Agent= adversary_1
Observation :  [-0.28718972 -0.10497354  0.47207174 -0.04327453 -1.1414672  -0.04603079
 -0.70463526  0.8114515   0.3487868  -0.12992594 -0.92126507  0.34744653
 -0.64496046  1.3983082  -0.26207972  0.4427374 ]
Reward: 0.0
Termination:  False
Truncation True
Selected Agent:  adversary_1
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

Agent= adversary_2
Observation :  [ 0.2938701   0.41768175 -0.44919336  0.304172   -0.22020212 -0.39347732
  0.21662979  0.464005    1.2700518  -0.47737247  0.92126507 -0.34744653
  0.27630463  1.0508616  -0.26207972  0.4427374 ]
Reward: 0.0
Termination:  False
Truncation True
Selected Agent:  adversary_2
Agent Observation Space:  Box(-inf, inf, (16,), float32)
Agent Action Space:  Discrete(5)
************************

Agent= agent_0
Observation :  [-0.26207972  0.4427374  -0.17288871  1.3550336  -0.49650675 -1.4443389
 -0.05967485 -0.58685666  0.99374723 -1.5282341   0.64496046 -1.3983082
 -0.27630463 -1.0508616 ]
Reward: -2.034128158475777
Termination:  False
Truncation True
Selected Agent:  agent_0
Agent Observation Space:  Box(-inf, inf, (14,), float32)
Agent Action Space:  Discrete(5)
************************

state_space =  Box(-inf, inf, (62,), float32)
observation_space =  {'adversary_0': Box(-inf, inf, (16,), float32), 'adversary_1': Box(-inf, inf, (16,), float32), 'adversary_2': Box(-inf, inf, (16,), float32), 'agent_0': Box(-inf, inf, (14,), float32)}
action_space =  {'adversary_0': Discrete(5), 'adversary_1': Discrete(5), 'adversary_2': Discrete(5), 'agent_0': Discrete(5)}
======================================
